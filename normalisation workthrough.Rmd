---
title: "Normalisation Script Revisited"
author: "Peter Ditchfield"
date: "08/07/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## An RMarkdown work though of Erica's normalisation script

Erika's normalization calculation and data-quality checking	srcipt is widely used in RLAHA but it hasn't been maintained for a long time. Many people use it but I dont know exactly what it does and how it works. So this is a work through to see if I can understand it more fully. Code and text from Erica's script are in *italics* my comments are in **bold** text

##  Actions of each section.

*#Section 1 getting the data into the script*

*1. Put your runfile's location in the quotation marks" Change nothing else in line 15.*

*<- remove this comment if using lab basement computer -> *

*setwd("C:/Users/Sercon_1/Desktop") # Place csv file on desktop*

*setwd("~/Dropbox Oxford/Dropbox/dropbox AGRICURB/Runfiles/160812")*
 

 
 
 
```{r}
name <- read.csv("160812.csv", header=F)[, c(1:3, 5, 6,9:11)] # this is her line 15

runfile.id <- "160812"
```

**So this just reads selected columns of the raw .csv data file into a table called name without the headders and creates a variable called runfile.id which is the run number**

*Section 2. Assign RM1 and RM2 the same character string as in your spreadsheet*
*RM1.name <- "SEAL2" # <- the name of your RM1 exactly as it is in the spreadsheet*
*RM2.name <- "USGS40" # <- the name of your RM2 exactly as it is in the spreadsheet*

```{r}
# 2. Assign RM1 and RM2 the same character string as in your spreadsheet.
RM1.name <- "SEAL2" # <- the name of your RM1 exactly as it is in the spreadsheet
RM2.name <- "USGS40" # <- the name of your RM2 exactly as it is in the spreadsheet
```

**This assigns the refernce materials (RM1, RM2) to the  known value reference materials used in the run to enable the two point correction.**

*#3. For RM1 and RM2, give the true d15N values relative to AIR and stdev obtained from literature*
*RM1T.N <- 17.3	  #RM1 d15N mean*
*RM1Tsd.N <- 0.29		#RM1 d15N standard deviation*
*RM2T.N <- -4.52 	# RM2 d15N mean*
*RM2Tsd.N <- 0.06	#RM2 d15N standard deviation*

```{r}
# 3. For RM1 and RM2, give the true d15N values relative to AIR and stdev obtained from literature
RM1T.N <- 17.3	  #RM1 d15N mean
RM1Tsd.N <- 0.29		#RM1 d15N standard deviation
RM2T.N <- -4.52 	# RM2 d15N mean
RM2Tsd.N <- 0.06	#RM2 d15N standard deviation
```

**This puts the known nitrogen isotope values and standard variations of the reference materials into the named variables.**

*#4. For RM1 and RM2, give the true d13C values relative to VPDB and stdev obtained from literature*
*RM1T.C <- -13.3	# RM1 d13C mean*
*RM1Tsd.C <- 0.11		# RM1 d13C standard deviation*
*RM2T.C <- -26.39 	# RM2 d13C mean* 
*RM2Tsd.C <- 0.04	# RM2 d13C standard deviation*

```{r}
# 4. For RM1 and RM2, give the true d13C values relative to VPDB and stdev obtained from literature
RM1T.C <- -13.3	# RM1 d13C mean
RM1Tsd.C <- 0.11		# RM1 d13C standard deviation
RM2T.C <- -26.39 	# RM2 d13C mean 
RM2Tsd.C <- 0.04	# RM2 d13C standard deviation

```

**This does the same for the carbon isotope values of the reference materials.**

*# 	Don't forget to change C RMs below		   #*

**I am not sure what she meant by this comment**

**the next section is not numbered**

*#	Formatting columns from raw data file	   #*

*# sets up a vector of integers from 1 to the number of rows in the csv file*
*rownumber <- (1:nrow(name))*
*# puts the undriftcorrected data into the table name2. starting at row 9* 
*# and truncating the end statment and its row number at the end of the undrift    corrected section*
*name2 <- name[9:((rownumber[name[,1]=="Drift Corrected"])-2),]*

*#puts the driftcorrected data from 4 rows beyond the drift corrected statment* *#to the end of the file into a table called name3* 
*name3 <- name[((rownumber[name[,1]=="Drift Corrected"])+4):nrow(name),]*

```{r}
#	Formatting columns from raw data file	   #
#
# sets up a vector of integers from 1 to the number of rows in the csv file
rownumber <- (1:nrow(name))
# puts the undriftcorrected data into the table name2. starting at row 9 
# and truncating the end statment and its row number at the end of the undrift #corrected section
name2 <- name[9:((rownumber[name[,1]=="Drift Corrected"])-2),]

#puts the driftcorrected data from 4 rows beyond the drift corrected statment 
#to the end of the file into a table called name3 
name3 <- name[((rownumber[name[,1]=="Drift Corrected"])+4):nrow(name),]
```

**This chunk puts the undrift corrected data into a data frame called name2 and the drift corrected data into a df called name3. It uses the 'drift corrected' statement in the original file as a marker to know where to stop and start in each case**
**it also sets up a vector of integers the same length as the whole csv file**

*strReverse <- function(x)*
  *sapply(lapply(strsplit(x, NULL), rev), paste, collapse="")*
*runname <- runfile.id*      
*data <- data.frame(name2,  name3[,4:8], rep(runname, nrow(name2)), rep(0,* *nrow(name2)),rep(0, nrow(name2)),rep(0, nrow(name2)))*

```{r}
strReverse <- function(x)
  sapply(lapply(strsplit(x, NULL), rev), paste, collapse="")
runname <- runfile.id      
data <- data.frame(name2,  name3[,4:8], rep(runname, nrow(name2)), rep(0, nrow(name2)),rep(0, nrow(name2)),rep(0, nrow(name2)))
```

**This reads runfile.id i.e. the run number into a variable called runname** 
**then makes a new df called data which has collumns from the undrift corrected and the drift correct parts of the csv file. It also adds some extra columns with rep inculding the run bumber and three columns of zeros**

**I dont know what the strReverse function is doing. It is a function to reverse character strings see examples in the strspilt help page for details, but I dont know what it is doing here. The only thing that might be worth reversing is the run number which when reveresed would give the date of the run**

*# add colunm names to the data.frame (data)*
*names(data) <- c("Ps", "ID", "Wt", "NugR", "d15NR", "CugR",* *"d13CR", "d18OR", "Nugdc", "d15Ndc", "Cugdc", "d13Cdc",* *"d18Odc", "Runfile", "pcC", "pcN", "CN")*

```{r}
# add colunm names to the data.frame (data)
names(data) <- c("Ps", "ID", "Wt", "NugR", "d15NR", "CugR", "d13CR", "d18OR", "Nugdc", "d15Ndc", "Cugdc", "d13Cdc", "d18Odc", "Runfile", "pcC", "pcN", "CN")

```

**this adds names to the columns in the df data, note dc is drift corrected but many of the columns are as factors so**

*#make numeric things numeric*
*for (i in c(1, 3:13, 15:17)){data[,i] <-* *as.numeric(as.character(data[,i]))}*

```{r}
#make numeric things numeric
for (i in c(1, 3:13, 15:17)){data[,i] <- as.numeric(as.character(data[,i]))}
```
 
 **this makes the columns that need to numeric into numeric..but by itteration rather than selecting and using the as.numeric function..prosibly because as they are factors they might return the underlying factor integer value which would not be helpful**
 
 *#Add pcC, pcN and CN ratio						#NB these are based on drift corrected values*
*data$pcC <- data$Cugdc/data$Wt/10*
*data$pcN <- data$Nugdc/data$Wt/10* 
*data$CN <- data$Cugdc/data$Nugdc***14/12*
```{r}
#Add pcC, pcN and CN ratio						#NB these are based on drift corrected values
data$pcC <- data$Cugdc/data$Wt/10
data$pcN <- data$Nugdc/data$Wt/10 
data$CN <- data$Cugdc/data$Nugdc*14/12
```
 
**this chunk  calculates and adds the weight percent C and N and the C/N molar ratio to the df data into the colmns filled with zeros that were made when the df was initiated**

*# This is removing some data points at pos 7, 38 and 55*
*# because in this particular run they have wrong values or*
*# are poor analyses....but only in this run!!!*
*data <- data[data$Ps!=7 & data$Ps!=38 & data$Ps!=55, ]*

```{r}
# This is removing some data points at pos 7, 38 and 55
# because in this particular run they have wrong values or
# are poor analyses....but only in this run!!!
data <- data[data$Ps!=7 & data$Ps!=38 & data$Ps!=55, ]
```

**this chunk removes the entries of the df data where position (Ps) =7, 38 and 55 as these are bad analyses in this run as can be seen from the original drift coreected data in the csv or the original .prn file output of the mass spec..So these positions are specific to this run only other runs may have other bad values or none at all**


**This next section deals with creating an archiev copy of the data with some extra data fields which  at one time we required in the lab but have given up on recently as it was not done by all users**

*# Create the archive copy*

*archive <- data.frame(samplename=data$ID, sampleweight = data$Wt, RS="S",* *owner="AS", PreparedBy ="AS", Funding="Bogaard ERC", sampletype=0, Taxa="",* *site="", age.context=0, ugN=data$Nugdc, d15N=data$d15Ndc, ugC=data$Cugdc,* *d13C=data$d13Cdc, CN=data$CN, labno = paste(runfile.id, data$Ps, sep="-"))*



```{r}
archive <- data.frame(samplename=data$ID, sampleweight = data$Wt, RS="S", owner="AS", PreparedBy ="AS", Funding="Bogaard ERC", sampletype=0, Taxa="", site="", age.context=0, ugN=data$Nugdc, d15N=data$d15Ndc, ugC=data$Cugdc, d13C=data$d13Cdc, CN=data$CN, labno = paste(runfile.id, data$Ps, sep="-"))


```

**this creates a new df called archive which has the data from the data df plus some extra fields such as owner, PreparedBy, Funding, sampletype, Taxa, site, age.context**

**It also asigins a lab number  in column labno by using the run.id and the run position (Ps) separated by a -**

*list.of.salanines <- data$Ps[archive$samplename=="SALANINE"]*
*first.s <- list.of.salanines[1]*
*first.r <- first.s-8*
*list.of.ralanines <- c(2, first.r, list.of.salanines)*
*archive$RS <- "S"*
*archive$RS[list.of.ralanines] <- "R"*

```{r}
list.of.salanines <- data$Ps[archive$samplename=="SALANINE"]
first.s <- list.of.salanines[1]
first.r <- first.s-8
list.of.ralanines <- c(2, first.r, list.of.salanines)
archive$RS <- "S"
#archive$RS[list.of.ralanines] <- "R"
```

**This makes a vector of the position of all the SALANINE's then stores the position of the first SALANINE in first.s**

**Then it stores the position of the first ref Alanine in first.r..note it relies on consitant spacing of ref alanines in the run it is not working out which are ref alanines.**

**Then it makes a vector of the position of the ref alanines in the run again only relying on constant spacing in the run and taking account that position 2 is a ref alanine.**

**Then it fills everything in the RS column of the df archive with an S but this is redundant as they are all declared S already but does no harm to make sure.**

**Then finaly it trys to replaces the S in the RS column with an R for the ref alanines in the run positions stored in list.of.ralanines...but this noes not work and throws an error as it trys to give an R to the RS of posion 67 whichwould be line 67 in the df this does not exists as we have deleted some bad values from the run and now the df is only 64 entries long.  Also the deleted values would throw off the consitant spacing of the ref alanines in the run..This error causes problems for the rmarkdown doc so I have comented out the offending line in the chunk above.**

*archive$sampletype[archive$samplename=="ALANINE" |archive$samplename=="SALANINE" | archive$samplename==paste(RM1.name) | archive$samplename==paste(RM2.name)] <- "Standard"*

*archive$sampletype[archive$samplename!="ALANINE" & archive$samplename!="SALANINE" & archive$samplename!=paste(RM1.name) & archive$samplename!=paste(RM2.name)] <- "Plant"*

*archive$age.context[archive$samplename=="ALANINE" |archive$samplename=="SALANINE" | archive$samplename==paste(RM1.name) | archive$samplename==paste(RM2.name)] <- "Modern"*

*archive$age.context[archive$samplename!="ALANINE" & archive$samplename!="SALANINE" & archive$samplename!=paste(RM1.name) & archive$samplename!=paste(RM2.name)] <- "Bronze Age"*


*names(archive) <- c("sample name", "sample weight", "R/S", "Owner", "Prepared by", "Funding", "Sample type", "Taxa", "Site", "age/context", "ug N", "d15N AIR", "ug C", "d13C VPDB", "C/N molar", "Lab number")*


```{r}
archive$sampletype[archive$samplename=="ALANINE" |archive$samplename=="SALANINE" | archive$samplename==paste(RM1.name) | archive$samplename==paste(RM2.name)] <- "Standard"

archive$sampletype[archive$samplename!="ALANINE" & archive$samplename!="SALANINE" & archive$samplename!=paste(RM1.name) & archive$samplename!=paste(RM2.name)] <- "Plant"

archive$age.context[archive$samplename=="ALANINE" |archive$samplename=="SALANINE" | archive$samplename==paste(RM1.name) | archive$samplename==paste(RM2.name)] <- "Modern"

archive$age.context[archive$samplename!="ALANINE" & archive$samplename!="SALANINE" & archive$samplename!=paste(RM1.name) & archive$samplename!=paste(RM2.name)] <- "Bronze Age"


names(archive) <- c("sample name", "sample weight", "R/S", "Owner", "Prepared by", "Funding", "Sample type", "Taxa", "Site", "age/context", "ug N", "d15N AIR", "ug C", "d13C VPDB", "C/N molar", "Lab number")

```

**This programtically fills in the sample type and age columns in the df archive with plant and brinze age for samples and standard and modern for alanines and the other references used RM1 and RM2**

**Then it tidies up the column names with the correct full names required by the old lab archive system**


*run.id <- matrix(nrow=2, ncol=16)*
*run.id[1, 1:2] <- c("Run number", paste(runfile.id))*
*run.id[2, 1:2] <- c("User", "Amy Styring")*
*run.id[1:2, 3:16] <- ""*
*run.id <- data.frame(run.id)*
*names(run.id) <- names(archive)*
*archive <- rbind(archive, run.id)*
*write.csv(archive, paste("archive", runfile.id, "csv", sep="."))*

```{r}
run.id <- matrix(nrow=2, ncol=16)
run.id[1, 1:2] <- c("Run number", paste(runfile.id))
run.id[2, 1:2] <- c("User", "Amy Styring")
run.id[1:2, 3:16] <- ""
run.id <- data.frame(run.id)
names(run.id) <- names(archive)
archive <- rbind(archive, run.id)
write.csv(archive, paste("archive", runfile.id, "csv", sep="."))
```

**This makes an empty 2x16 matrix called run.id, it then puts the string 'Run number and the run file id in this case 160812 into the first two positions of the first row of the matrix.** 
**Then it puts the strings User and Amy Styring into the first two positions of the second line of the matrix**
**Then it puts pairs of quotation marks in the remaining positions in lines 1 and 2 of the matrix**
**Then it turns the 2x16 matrix into a data frame called run.id and call the coulnms the same names as used in the archive df so that it can then append the df run.id to the df archive**
**Finaly it writes the new archieve df out to a .csv file called archiev.160812.csv**

*data2 <- read.csv(paste("archive", runfile.id, "csv", sep="."), header=F)*

```{r}
data2 <- read.csv(paste("archive", runfile.id, "csv", sep="."), header=F)

```

**this reads the recently created .csv file (using it programatically created name) into a df called data2**
**the following section tidies up the file format, moves the run number and the user name to the top and outputs the final.archive csv file**

*bottom <- nrow(data2)*
*run.id <- data2[(bottom-1):bottom, ]*
*just.data <- data2[1:(bottom-2), ]*
*final.archive <- rbind(run.id[2:17], just.data[2:17])*
*write.csv(final.archive, paste("final.archive", runfile.id, "csv", sep="."), row.names=FALSE)*

```{r}

bottom <- nrow(data2)
run.id <- data2[(bottom-1):bottom, ]
just.data <- data2[1:(bottom-2), ]
final.archive <- rbind(run.id[2:17], just.data[2:17])
write.csv(final.archive, paste("final.archive", runfile.id, "csv", sep="."), row.names=FALSE)


```

**This stores the number of rows of data2 into the variable bottom then uses that variable to index the last two lines of data2 and replaces the previous contents of run.id df with the 2 last lines of data2**
**then it takes all except the last 2 lines of the df data2 and reads them into a df called just.data with the column names now as the first row of the actual df rather than as headders..clever**

**Then it appends columns 2:17 of just data to columns 2:17 of run id and reads this into the df called final.archive**
**lastly it writes this out to a .csv file programatically named final.archive_ (run number).csv in this casefinal.archive_160812.csv**

## Now the normalisation part begins

### Step 1 : Pre-calculate all of the means and stdevs of the standards

*# add columns for these to the dataframe and fill with 0's*
*normd15N <- rep(0, length(data$d15Ndc))*
*d15Nsd <- rep(0, length(data$d15Ndc))*
*data <- data.frame(data, normd15N, d15Nsd)*
```{r}

# add columns for these to the dataframe and fill with 0's
normd15N <- rep(0, length(data$d15Ndc))
d15Nsd <- rep(0, length(data$d15Ndc))
data <- data.frame(data, normd15N, d15Nsd)
```

**This adds in the empty columns for the mean and sd of the drift corrected 15N values for the standards and fills them with zeros**

*# calculate the means and sd of RM1 and RM2*
*RM1M <- mean(data$d15Ndc[data$ID==paste(RM1.name)])*
*RM2M <- mean(data$d15Ndc[data$ID==paste(RM2.name)])* 
*RM1Msd <- sd(data$d15Ndc[data$ID==paste(RM1.name)])*
*RM2Msd <- sd(data$d15Ndc[data$ID==paste(RM2.name)])*

```{r}
# calculate the means and sd of RM1 and RM2
RM1M <- mean(data$d15Ndc[data$ID==paste(RM1.name)])
RM2M <- mean(data$d15Ndc[data$ID==paste(RM2.name)]) 
RM1Msd <- sd(data$d15Ndc[data$ID==paste(RM1.name)])
RM2Msd <- sd(data$d15Ndc[data$ID==paste(RM2.name)])

```

**This chunk programatically finds the values for 15N for the  scale compression reference samples and calculates mean and sd for them and stores them in appropiately named variables** 

*#calculate the mean and sd of the salanine results*
*alaninesd <- sd(data$d15Ndc[data$ID=="SALANINE" & data$Ps > 10])*
*mean.alanine <- mean(data$d15Ndc[data$ID=="SALANINE" & data$Ps > 10])*

```{r}
#calculate the mean and sd of the salanine results
alaninesd <- sd(data$d15Ndc[data$ID=="SALANINE" & data$Ps > 10])
mean.alanine <- mean(data$d15Ndc[data$ID=="SALANINE" & data$Ps > 10])
```

**This chunk calculates the mean and sd of all the SALANINEs in the df data where run position Ps is > 10 so avoiding the warm up Alanines at the start of the run although these are not called SALANINE in this run so would have been ignored anyway**

##Now the real work begins
##Firstly for the N15 results

*## Step 2: Normalize data and calculate uncertainties*
*## This is based on Kragten's spreadsheet*

*for (i in 1:nrow(data)){*
  *x1 <- data$d15Ndc[i]*
  *measuredcolumn <- c(RM1T.N, RM1M, RM2T.N, RM2M, x1)*
  *matrix1 <- cbind(c(RM1Tsd.N, 0, 0, 0, 0),* 
                   *c(0, RM1Msd, 0, 0, 0),* 
                   *c(0, 0, RM2Tsd.N, 0, 0),* 
                   *c(0, 0, 0,RM2Msd, 0),*
                   *c(0,0,0,0,alaninesd))*
  *matrix2 <- rbind(rep(RM1T.N, 5), rep(RM1M, 5), rep(RM2T.N, 5), rep(RM2M, 5), rep(x1, 5))*
  *matrix3 <- matrix1 + matrix2*
  *raw2true <- function(cv) {cv[1] +* *(cv[5]-cv[2])***((cv[1]-cv[3])/(cv[2]-cv[4]))}*
  *dsqr <- function(colno){(raw2true(matrix3[,colno])-raw2true(measuredcolumn))^2}*
  *normalizedd15N <- raw2true(measuredcolumn)*
  *finalerror <- sqrt(dsqr(1)+dsqr(2)+dsqr(3)+dsqr(4)+dsqr(5))*
  *data$d15Nsd[i]<- finalerror*
  *data$normd15N[i] <- normalizedd15N*
*}*



```{r}
## Step 2: Normalize data and calculate uncertainties
## This is based on Kragten's spreadsheet

for (i in 1:nrow(data)){
  x1 <- data$d15Ndc[i]
  measuredcolumn <- c(RM1T.N, RM1M, RM2T.N, RM2M, x1)
  matrix1 <- cbind(c(RM1Tsd.N, 0, 0, 0, 0), 
                   c(0, RM1Msd, 0, 0, 0), 
                   c(0, 0, RM2Tsd.N, 0, 0), 
                   c(0, 0, 0,RM2Msd, 0),
                   c(0,0,0,0,alaninesd))
  matrix2 <- rbind(rep(RM1T.N, 5), rep(RM1M, 5), rep(RM2T.N, 5), rep(RM2M, 5), rep(x1, 5))
  matrix3 <- matrix1 + matrix2
  raw2true <- function(cv) {cv[1] + (cv[5]-cv[2])*((cv[1]-cv[3])/(cv[2]-cv[4]))}
  dsqr <- function(colno){(raw2true(matrix3[,colno])-raw2true(measuredcolumn))^2}
  normalizedd15N <- raw2true(measuredcolumn)
  finalerror <- sqrt(dsqr(1)+dsqr(2)+dsqr(3)+dsqr(4)+dsqr(5))
  data$d15Nsd[i]<- finalerror
  data$normd15N[i] <- normalizedd15N
}
```

**This starts a for loop for evry row in the df data it reads the drift corrected value of d15 N into the variable x1**

**Then it reads the true d15N value of RM1 the measured d15N value of RM1 the true d15N value of RM2, the measued value of RM2 and the current value of x1 into the vector measuredcolumn**

**Then it builds a 5x5 matrix called matrix1 with the sd values for RM1T, RM1M, RM2T, RM2M and alaninesd down the leading diagonal**

**Then it builds another 5x5 matrix called matrix2 with the  true d15N value for RM1 repeated five times in the first row the d15N value for RM1M repeated five times in the second row. The true d15N value for RM2 repeated r times in the third row. The value for RM2M five times in the fouth row and the current value for x1 repeated five times in the fith row**

**then it creates a third 5x5 matrix called matrix3 by addition of matrix1 and matrix2, such that matrix 3 has the sd + the d15N value down the leading diagonal and d15N value of RM1T, RM1M, RM2T, RM2M and current value of x1 in each of the other positions in the rows respectively**

**it then defines a function raw2true.This takes a vector of five values cv1 to cv5 and makes a calculation with them. It will apply it to the veror measuredcolumn to calculate a normalised value thus**
**normalised value = RM1T + (current x1 - RM1M) x ((RM1T-RM2T) / (RM1M-RM2M))**

**(RM1T-RM2T) / (RM1M-RM2M) is the gradient of the calibration line between the two known references materials and their measured values. current value of x1 is the raw data point we are calibrating in this itteration of the loop. This is how it performs the normalisation calibration It DOES NOT fit an explicit linear modle using least squares but it uses the well known two point braceting standards calibration equation see paul et al 2007 for example**.

**next it defines another function  called dsqr**
**This performs the raw2true function on each coloum of matrix3 and subtracts the raw2true result of the vector measuredcolumn from that and squares the result**

**Having set up the loop, the matrixes and the functions it then chugs through the loop for each  drift corrected value of N15 in the df data and stores the values in the df data in the normal15N column in the df data. It also calculates a value for final error by applying dsqr to each column of matrix 3, suming the values and taking the square root. which it then stores in the d15sd column in the df data. again using the equation for th propagation of error for the bracketing standard point calibration method see the SiCAlib progam manual for example**

##Then we do the same proces but for the 13C results

## Step 1 : Pre-calculate all of the means and stdevs of the standards
*normd13C <- rep(0, length(data$d13Cdc))*
*d13Csd <- rep(0, length(data$d13Cdc))*
*data <- data.frame(data, normd13C, d13Csd)*

*RM1M <- mean(data$d13Cdc[data$ID==paste(RM1.name)]) # Make sure to select the correct RM!*
*RM2M <- mean(data$d13Cdc[data$ID==paste(RM2.name)]) # Make sure to select the correct RM!*
*RM1Msd <- sd(data$d13Cdc[data$ID==paste(RM1.name)])*
*RM2Msd <- sd(data$d13Cdc[data$ID==paste(RM2.name)])*
*alaninesd <- sd(data$d13Cdc[data$ID=="SALANINE" & data$Ps > 10])*
*mean.alanine <- mean(data$d13Cdc[data$ID=="SALANINE" & data$Ps > 10])*


```{r}
## Step 1 : Pre-calculate all of the means and stdevs of the standards
normd13C <- rep(0, length(data$d13Cdc))
d13Csd <- rep(0, length(data$d13Cdc))
data <- data.frame(data, normd13C, d13Csd)

RM1M <- mean(data$d13Cdc[data$ID==paste(RM1.name)]) # Make sure to select the correct RM!
RM2M <- mean(data$d13Cdc[data$ID==paste(RM2.name)]) # Make sure to select the correct RM!
RM1Msd <- sd(data$d13Cdc[data$ID==paste(RM1.name)])
RM2Msd <- sd(data$d13Cdc[data$ID==paste(RM2.name)])
alaninesd <- sd(data$d13Cdc[data$ID=="SALANINE" & data$Ps > 10])
mean.alanine <- mean(data$d13Cdc[data$ID=="SALANINE" & data$Ps > 10])

```

**Note this redifnes RM1M, RM2M, RM1Msd, RM2Msd, alaninesd and mean.alanine to be the relavent measured 13C values**
**it also adds the blank columns for the corected c data into the df data**

*## Step 2: Normalize data and calculate uncertainties*
*## This is based on Kragten's spreadsheet*
*for (i in 1:nrow(data)){*
  *x1 <- data$d13Cdc[i]*
  *measuredcolumn <- c(RM1T.C, RM1M, RM2T.C, RM2M, x1)*
  *matrix1 <- cbind(c(RM1Tsd.C, 0, 0, 0, 0),* 
                   *c(0, RM1Msd, 0, 0, 0),* 
                   *c(0, 0, RM2Tsd.C, 0, 0),* 
                   *c(0, 0, 0,RM2Msd, 0),*
                   *c(0,0,0,0,alaninesd))*
  *matrix2 <- rbind(rep(RM1T.C, 5), rep(RM1M, 5), rep(RM2T.C, 5),* *rep(RM2M, 5), rep(x1, 5))*
  *matrix3 <- matrix1 + matrix2*
  *raw2true <- function(cv) {cv[1] +* *(cv[5]-cv[2])***((cv[1]-cv[3])/(cv[2]-cv[4]))}*
  *dsqr <- function(colno){(raw2true(matrix3[,colno])-raw2true(measuredcolumn))^2}*
  *normalizedd13C <- raw2true(measuredcolumn)*
  *finalerror <- sqrt(dsqr(1)+dsqr(2)+dsqr(3)+dsqr(4)+dsqr(5))*
  *data$d13Csd[i]<- finalerror*
  *data$normd13C[i] <- normalizedd13C*
*}*

```{r}
## Step 2: Normalize data and calculate uncertainties
## This is based on Kragten's spreadsheet
for (i in 1:nrow(data)){
  x1 <- data$d13Cdc[i]
  measuredcolumn <- c(RM1T.C, RM1M, RM2T.C, RM2M, x1)
  matrix1 <- cbind(c(RM1Tsd.C, 0, 0, 0, 0), 
                   c(0, RM1Msd, 0, 0, 0), 
                   c(0, 0, RM2Tsd.C, 0, 0), 
                   c(0, 0, 0,RM2Msd, 0),
                   c(0,0,0,0,alaninesd))
  matrix2 <- rbind(rep(RM1T.C, 5), rep(RM1M, 5), rep(RM2T.C, 5), rep(RM2M, 5), rep(x1, 5))
  matrix3 <- matrix1 + matrix2
  raw2true <- function(cv) {cv[1] + (cv[5]-cv[2])*((cv[1]-cv[3])/(cv[2]-cv[4]))}
  dsqr <- function(colno){(raw2true(matrix3[,colno])-raw2true(measuredcolumn))^2}
  normalizedd13C <- raw2true(measuredcolumn)
  finalerror <- sqrt(dsqr(1)+dsqr(2)+dsqr(3)+dsqr(4)+dsqr(5))
  data$d13Csd[i]<- finalerror
  data$normd13C[i] <- normalizedd13C
}
```

**this applies the same normalisation and error propagation equations for the bracketing standards calibration method as were used for the N calibration above**

**then it does a bit of tidying up**
**by creating the following variables but with a .C identifer**

*RM1M.C <- RM1M*
*RM2M.C <- RM2M*
*RM1Msd.C <- RM1Msd*
*RM2Msd.C <- RM2Msd*

```{r}
RM1M.C <- RM1M
RM2M.C <- RM2M
RM1Msd.C <- RM1Msd
RM2Msd.C <- RM2Msd	
```


**note it did not do this for the N related values which would have been more tidy**

## then it writes out the data file with all the data

*write.csv(data, "Alldata.csv")*

```{r}
write.csv(data, "Alldata.csv")

```


## checking the quality of the data, the standards and the normalisation


